
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="My personal Notes">
      
      
        <meta name="author" content="Nithish Duvvuru">
      
      
        <link rel="canonical" href="https://nithish96.github.io/Books/UDL/12.%20Transformers/">
      
      
        <link rel="prev" href="../08.%20Measuring%20Performance/">
      
      
        <link rel="next" href="../../transformers/0.intro/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.30">
    
    
      
        <title>12. Transformers - Nithish Duvvuru</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Nithish Duvvuru" class="md-header__button md-logo" aria-label="Nithish Duvvuru" data-md-component="logo">
      
  <img src="../../../img/logo.bmp" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Nithish Duvvuru
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              12. Transformers
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/nithish96/nithish96.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    nithish96/nitish96.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Nithish Duvvuru" class="md-nav__button md-logo" aria-label="Nithish Duvvuru" data-md-component="logo">
      
  <img src="../../../img/logo.bmp" alt="logo">

    </a>
    Nithish Duvvuru
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/nithish96/nithish96.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    nithish96/nitish96.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Books
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Books
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLM From Scratch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            LLM From Scratch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%202/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Working with Text Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%203/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Coding Attention Mechanisms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%204/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Implementing a GPT Model from Scratch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%205/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Pretraining on Unlabeled Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%206/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Fine-tuning for Classification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../LLM%20From%20Scratch/Chapter%207/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Fine-Tuning to Follow Instructions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    UDL
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            UDL
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00.%20Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    00. Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05.%20Loss%20Functions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    05. Loss Functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08.%20Measuring%20Performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    08. Measuring Performance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    12. Transformers
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    12. Transformers
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Dot Product Self Attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dot Product Self Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#computing-and-weighting-values" class="md-nav__link">
    <span class="md-ellipsis">
      Computing and Weighting Values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computing-attention-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Computing Attention Weights
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extensions-to-dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Extensions to dot-product self-attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Extensions to dot-product self-attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#positional-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Positional encoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaled-dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled dot product self-attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-heads" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple heads
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Layers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformers-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers for NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformers/0.intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    0. Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformers/1.transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformers/2.bert/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. BERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformers/3.modifications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Modifications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformers/4.applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Applications
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Computer Vision
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Computer Vision
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Concepts
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Concepts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/Concepts/Attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/Concepts/CTC%20Decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CTC Decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text Detection
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Text Detection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/Text%20Detection/craft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CRAFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/Text%20Detection/dbnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DBNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text Recognition
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Text Recognition
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/Text%20Recognition/vitstr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViTSTR
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/transformers/Data-efficient%20Image%20Transformer%20%28DeiT%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data efficient Image Transformer (DeiT)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/transformers/detr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Detection Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/transformers/swin/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Swin Transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Computer%20Vision/transformers/vit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Languages
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Languages
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Languages/python/Multiprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multiprocessing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Languages/python/pandas/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pandas
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Languages/python/threading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Threading
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    MLOps
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            MLOps
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MLOps/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../MLOps/kubernetes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kubernetes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    NLP
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            NLP
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_1" >
        
          
          <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Courses
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Courses
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/Courses/stanford/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Standford
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLM
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1" id="__nav_6_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    LLAMA
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1">
            <span class="md-nav__icon md-icon"></span>
            LLAMA
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/LLM/LLAMA/3.pretraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. PreTraining
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/LLM/LLAMA/4.posttraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Post Training
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/LLM/LLAMA/6.Inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/LLM/LLAMA/7.vision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Vision
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/LLM/LLAMA/8.speech/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Speech
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Dot Product Self Attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dot Product Self Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#computing-and-weighting-values" class="md-nav__link">
    <span class="md-ellipsis">
      Computing and Weighting Values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#computing-attention-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Computing Attention Weights
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extensions-to-dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Extensions to dot-product self-attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Extensions to dot-product self-attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#positional-encoding" class="md-nav__link">
    <span class="md-ellipsis">
      Positional encoding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaled-dot-product-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      Scaled dot product self-attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiple-heads" class="md-nav__link">
    <span class="md-ellipsis">
      Multiple heads
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-layers" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Layers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformers-for-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers for NLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>12. Transformers</h1>

<h2 id="introduction">Introduction</h2>
<p>In recent years, the Transformer architecture has emerged as a game-changer in the field of natural language processing (NLP), transforming the landscape of machine translation, text generation, and a myriad of other tasks. Originally introduced by Vaswani et al. in their seminal paper "Attention Is All You Need" in 2017, the Transformer has rapidly become the de facto standard for state-of-the-art NLP models. </p>
<p>Transformer architecture comprises of several key components, including the encoder, decoder, self-attention mechanism, multi-head attention, positional encoding, and feed-forward neural network. Let's delve deeper into the intricacies of the aforementioned components.</p>
<h2 id="dot-product-self-attention">Dot Product Self Attention</h2>
<p>A standard neural network layer <span class="arithmatex">\(f[x]\)</span> takes a D × 1 input x and applies a linear transformation followed by an activation function like a ReLU, so 
    $$ f[x] = ReLU[\beta + \Omega [x]] $$ where <span class="arithmatex">\(\beta\)</span> contains biases and <span class="arithmatex">\(\Omega\)</span> contains the weights</p>
<p>Self Attention block <span class="arithmatex">\(sa[.]\)</span> takes N inputs <span class="arithmatex">\(x_1, x_2...x_N\)</span> each of dimension Dx1 and returns N output vectors of same size. In the context of NLP, each input represents a word or word fragment.  Set of values is computed for each input  $$ v_m = \beta_v + \Omega_vx_m $$ Then the <span class="arithmatex">\(n^{th}\)</span> output is weighted sum of all the values <span class="arithmatex">\(v_1, v_2, .... v_N\)</span>.<br />
$$ sa_n[x_1, ..., x_N]= \sum\limits_{m=1}^{N} a[x_m, x_n]v_m $$ 
The scalar weight <span class="arithmatex">\(a[x_m, x_n]\)</span> is the attention that <span class="arithmatex">\(n^{th}\)</span> output pays to input <span class="arithmatex">\(x_m\)</span>. N weights <span class="arithmatex">\(a[.,x_n]\)</span> are non-negative and sum to 1.  Hence, self-attention can be thought of as routing the values in different proportions to create each output. </p>
<h3 id="computing-and-weighting-values">Computing and Weighting Values</h3>
<p>Weights <span class="arithmatex">\(\Omega_v\)</span> and Biases <span class="arithmatex">\(\beta_v\)</span> are applied to each input.  Hence it scales linearly with sequence length N unlike fully connected layers mapping all D*N inputs at once. The value computation can be viewed as a sparse matrix operation with shared parameters. </p>
<p>Attention weights <span class="arithmatex">\(a[x_m, x_n]\)</span> combine the values from different inputs. It follows that the number of attention weights has a quadratic dependence on the sequence length N, but is independent of the length D of each input <span class="arithmatex">\(x_n\)</span>. </p>
<h3 id="computing-attention-weights">Computing Attention Weights</h3>
<p>We saw that the outputs result from two chained linear transformations.  Value vectors <span class="arithmatex">\(\beta_v + \Omega_vx_m\)</span> are computed independently for each input <span class="arithmatex">\(x_m\)</span>.  These vectors are linearly combined by the attention weights <span class="arithmatex">\(a[x_m, x_n]\)</span>. </p>
<p>To compute the attention weights we apply two more linear transformation to the inputs 
$$
    \begin{align}
        q_n = \beta_q + \Omega_qx_n \
        k_m = \beta_k + \Omega_kx_m
    \end{align}
$$</p>
<p>where <span class="arithmatex">\(q_n\)</span> and <span class="arithmatex">\(k_m\)</span> are called queries and keys respectively.  We compute the dot product of queries and keys and pass that through softmax function. </p>
<div class="arithmatex">\[
    \begin{align}
        a[x_m, x_n] &amp;= softmax[k_.^T . q_n] \\
                    &amp;= \frac{exp[k_m^T . q_n]}{\sum\limits_{m^{1}=1}^{N} exp[k_{m^1}^T] . q_n}
    \end{align}
\]</div>
<p>For each <span class="arithmatex">\(x_n\)</span> attention scores are positive and sum to 1. This is known as dot product self attention. </p>
<p>Dot product returns the similarity of its inputs. So the attention scores <span class="arithmatex">\(a[x_., x_n]\)</span> depend on the relative similarity between <span class="arithmatex">\(n^{th}\)</span> query and all of the keys. Softmax operation means the vectors compete to contribute to the final result. Queries and Keys must be of same dimension and this dimension can differ from that of values. </p>
<h2 id="extensions-to-dot-product-self-attention">Extensions to dot-product self-attention</h2>
<p>In dot product self attention,  the computation is the same regardless of the order of the inputs <span class="arithmatex">\(x_n\)</span>. However, order is important when the inputs correspond to the words in a sentence. </p>
<h3 id="positional-encoding">Positional encoding</h3>
<p>Positional encoding is a technique used to inject information about the position of tokens in a sequence into the input embeddings. The positional encoding is added to the input embeddings before feeding them into the Transformer encoder or decoder. </p>
<p>One commonly used method for positional encoding is the sine and cosine functions. The positional encoding matrix P for a sequence of length L and embedding dimension d is computed as follows:</p>
<div class="arithmatex">\[
\begin{align*}
P_{(pos, 2i)} = \sin\left(\frac{{pos}}{{10000^{2i/d}}}\right) \\
 P_{(pos, 2i+1)} = \cos\left(\frac{{pos}}{{10000^{2i/d}}}\right)
\end{align*}
\]</div>
<p>Where:</p>
<ul>
<li>pos is the position of the token in the sequence.</li>
<li>i is the dimension of the embedding.</li>
<li>d is the embedding dimension.</li>
</ul>
<p>Using positional encoding, Transformers can effectively capture the sequential order of tokens in the input sequence, enabling them to process sequential data such as natural language text more effectively.</p>
<h3 id="scaled-dot-product-self-attention">Scaled dot product self-attention</h3>
<p>The dot products in the attention computation can have large magnitudes and move the arguments to the softmax function into a region where the largest value completely dominates. Small changes to the inputs to the softmax function now have little effect on the output making the model diﬀicult to train. To prevent this, the dot products are scaled by the square root of the dimension <span class="arithmatex">\(D_q\)</span> of the queries and keys. </p>
<h3 id="multiple-heads">Multiple heads</h3>
<p>Multiple self-attention mechanisms are usually applied in parallel, and this is known as multi-head self-attention. Now H different sets of values, keys, and queries are computed:</p>
<div class="arithmatex">\[
    \begin{align}
        V_h &amp;= \beta_{vh}1^T + \Omega_{vh}X \\ 
        Q_h &amp;= \beta_{qh}1^T + \Omega_{qh}X \\ 
        K_h &amp;= \beta_{kh}1^T + \Omega_{kh}X \\
    \end{align}
\]</div>
<div class="arithmatex">\[
    sa_h[x] = V_h. Softmax[\frac{K_h^T . Q_h}{\sqrt D_q}]
\]</div>
<p>where we have different parameters  of values - <span class="arithmatex">\((\beta_{vh}, \Omega_{vh})\)</span>, queries -<span class="arithmatex">\((\beta_{qh}, \Omega_{qh})\)</span>, Keys - <span class="arithmatex">\((\beta_{kh}, \Omega_{kh})\)</span> for each head. </p>
<p>Typically, if the dimension of the inputs <span class="arithmatex">\(x_m\)</span> is D and there are H heads, the values, queries, and keys will all be of size D/H.  The outputs of these self-attention mechanisms are vertically concatenated, and another linear transform <span class="arithmatex">\(\Omega_c\)</span> is applied to combine them. </p>
<p>Multiple heads seem to be necessary to make self-attention work well. It has been speculated that they make the self-attention network more robust to bad initializations.</p>
<h2 id="transformer-layers">Transformer Layers</h2>
<p>Transformer layer consists of multi-head self attention unit followed by a fully  connected network <span class="arithmatex">\(mlp[x_.]\)</span>.  Both units are residual networks. In addition, it is typical to add a LayerNorm operation after both the self-attention and fully connected networks. This is similar to BatchNorm but uses statistics across the tokens within a single input sequence to perform the normalization. </p>
<p>Transformer layer can be described as </p>
<div class="arithmatex">\[
\begin{align}
    X &amp;\leftarrow X + MhSa[X] \\
    X &amp;\leftarrow LayerNorm[x] \\ 
    x_n &amp;\leftarrow x_n + mlp[x_n] \\ 
    X &amp;\leftarrow LayerNorm[X] \\ 
\end{align}
\]</div>
<p>where the column vectors <span class="arithmatex">\(x_n\)</span>are separately taken from the full data matrix X. </p>
<h2 id="transformers-for-nlp">Transformers for NLP</h2>
<p>A typical NLP pipeline starts with a tokenizer that splits the text into words or word fragments. Then each of the token is mapped to a learned embedding. These embeddings are passed through a series of transformer layers</p>
<ul>
<li>Tokenization<ul>
<li>This splits the text into smaller constituent units (tokens) from a vocabulary of possible tokens.  </li>
<li>In practice, a compromise between letters and full words is used, and the final vocabulary includes both common words and word fragments from which larger and less frequent words can be composed.</li>
<li>The vocabulary is computed using a sub-word tokenizer such as byte pair encoding  that greedily merges commonly occurring sub-strings based on their frequency.</li>
</ul>
</li>
<li>Embeddings<ul>
<li>Each token in the vocabulary V is mapped to a unique word embedding, and the embed- dings for the whole vocabulary are stored in a matrix <span class="arithmatex">\(\Omega_e \in R^{D \times |V|}\)</span></li>
<li>The input embeddings are computed as <span class="arithmatex">\(X=\Omega_e T\)</span> and <span class="arithmatex">\(\Omega_e\)</span> is learned like any other network parameter. </li>
<li>A typical embedding size D is 1024, and a typical total vocabulary size |V| is 30,000, so even before the main network, there are many parameters in <span class="arithmatex">\(\Omega_e\)</span> to learn.</li>
</ul>
</li>
<li>Transformer<ul>
<li>Finally, the embedding matrix X representing the text is passed through a series of K transformer layers, called a transformer model. </li>
<li>There are three types of transformer models.<ul>
<li>An encoder transforms the text embeddings into a representation that can support a variety of tasks</li>
<li>A decoder predicts the next token to continue the input text </li>
<li>Encoder-decoders are used in sequence-to-sequence tasks, where one text string is converted into another. </li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="references">References</h2>
<ol>
<li><a href="https://udlbook.github.io/udlbook/">Understanding Deep Learning</a></li>
<li><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">Positional Encoding </a></li>
<li><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a></li>
<li><a href="https://theaisummer.com/transformer/">Transformer</a></li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../08.%20Measuring%20Performance/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 08. Measuring Performance">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                08. Measuring Performance
              </div>
            </div>
          </a>
        
        
          
          <a href="../../transformers/0.intro/" class="md-footer__link md-footer__link--next" aria-label="Next: 0. Introduction">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                0. Introduction
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.footer", "navigation.instant", "navigation.top", "content.code.annotate", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>